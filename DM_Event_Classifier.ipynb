{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e9a356e",
   "metadata": {},
   "source": [
    "#### <p style=\"text-align: center; font-family:cm; font-size:1.8em;\">Machine Learning for Dark Matter Signal Classification</p>\n",
    "\n",
    "<p style=\"font-family:cm; font-size:1.3em; text-align: center\"><b>Owner:</b> Lucas Rocha Castro</p>\n",
    "\n",
    "<p style=\"font-family:cm; font-size:1em;\"> \n",
    "In the process of searching dor a possible Dark Matter (DM) particle, astrophysical observations are one of the pilars of DM indirect detection. When a target is observed, however, it is well known that noise may interfere with the obtained signal, and it is really important to develop strategies in order to be able to separate what is a potential DM particle signal and what is noisy, not usable data. In this project, I stablished a separation system that is simplified, yet physically relevant, taking into account the characteristics of the received signal, such as: the energy received; the angle at which it was intercepted; the particle's velocity and others.\n",
    "Using this separation, I generated many simulated data points using basic Python functions, and developed a trained algorithm using basic Machine Learning (ML) to evaluate if the machine was able to identify the two type of potential signals or not. \n",
    "It is a simple and yet useful project. As an undergraduate in Physics, my main objective is to be able to study ML and other computer science topics while integrating it with my currently researched topics: Dark Matter, Cosmology and Astrophysics.\n",
    "</p>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a8d32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import maxwell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175cd552",
   "metadata": {},
   "source": [
    "#### <p style=\"text-align: center; font-family:cm; font-size:1.8em;\">Data simulation</p>\n",
    "\n",
    "<p style=\"font-family:cm; font-size:1em;\"> \n",
    "I will be following a simplified model to identify what really should be Dark Matter signals versus what is background noise. To <b>Dark Matter</b> signal: <br>\n",
    "- $E$ (energy) will be a normal distribution with its peak located at ~50GeV, a reasonable value when dealing with indirect detection, such as Gamma Rays. <br>\n",
    "- $v$ (velocity) will follow a Maxwell-Boltzmann distribution, because according to the Standard Halo Model, the DM particles form an isotropical gas in gravitational equilibrium. Its scale is due to the Sun's velocity around the Galactic Center, which is $v_{\\odot} = 220 km/s$. <br>\n",
    "- $\\theta$, as the angle at which those particles are received. Note that it is not isotropic due to the Sun's orbit around the GC, and that causes a type of \"dark matter wind\", at which there is in fact a prefered angle. <br>\n",
    "- $\\phi$ represents the rotational symmetry due to the Halo's format. <br>\n",
    "- $r$ represents a DM model that decays exponentially. It is indeed not the current model used (such as NFW, Einasto, Moore, etc.) but in this case, to simplify the analysis and not deal with major computational problems, it is a great approximation. <br>\n",
    "<br>\n",
    "In contrast, the majority of <b>background data</b> is distributed on a uniform dataset, which is due to its homogeneity and isotropy, without any peaks because it has no specific events and, furthermore, it is a mix of different processes (radioactivity, cosmic rays, equipment noise and more), which brings a lot of randomness to all parameters.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f48d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataset \n",
    "def generate_dm_events(N): \n",
    "    E = np.random.normal(loc=50, scale=10, size=N) \n",
    "    v = maxwell.rvs(scale=220, size=N) \n",
    "    theta = np.random.normal(loc=np.pi/2, scale=0.4, size=N) \n",
    "    phi = np.random.uniform(0, 2*np.pi, size=N) \n",
    "    r = np.random.exponential(scale=8, size=N) \n",
    "    \n",
    "    return pd.DataFrame({ \"E\": E, \n",
    "                         \"v\": v, \n",
    "                         \"theta\": theta, \n",
    "                         \"phi\": phi, \n",
    "                         \"r\": r, \n",
    "                         \"label\": 1 })\n",
    "\n",
    "def generate_noise(N):\n",
    "    E = np.random.exponential(scale=40, size=N) \n",
    "    v = np.random.uniform(0, 600, size=N) \n",
    "    theta = np.random.uniform(0, np.pi, size=N) \n",
    "    phi = np.random.uniform(0, 2*np.pi, size=N) \n",
    "    r = np.random.uniform(0, 20, size=N) \n",
    "    \n",
    "    return pd.DataFrame({ \"E\": E, \n",
    "                         \"v\": v, \n",
    "                         \"theta\": theta, \n",
    "                         \"phi\": phi, \n",
    "                         \"r\": r, \n",
    "                         \"label\": 0 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ca899fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              E           v     theta       phi          r  label\n",
      "0     32.504969  263.554105  1.633818  4.059652   9.502593      1\n",
      "1     70.505350  440.065908  1.430398  0.198448   2.488079      1\n",
      "2     76.303426   39.214499  2.159585  5.692631  16.970669      0\n",
      "3     67.324164  222.361100  1.114934  1.528095   7.310751      1\n",
      "4     63.967292  229.535305  1.463561  0.741932   1.680408      1\n",
      "...         ...         ...       ...       ...        ...    ...\n",
      "9995  86.780548  182.831430  0.526465  2.735062  16.565572      0\n",
      "9996  47.792378  336.135406  1.295064  1.155807   2.007851      1\n",
      "9997  21.003633    1.697465  2.792971  6.069804   8.857137      0\n",
      "9998  68.310034  409.505989  1.515738  3.041167   4.201955      1\n",
      "9999  52.600210  192.713379  1.665927  2.212616   0.891741      1\n",
      "\n",
      "[10000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "N = 5000\n",
    "dm = generate_dm_events(N)\n",
    "bg = generate_noise(N)\n",
    "\n",
    "data = pd.concat([dm, bg]).sample(frac=1).reset_index(drop=True) \n",
    "data.to_csv(\"events.csv\", index=False)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b42763",
   "metadata": {},
   "source": [
    "#### <p style=\"text-align: center; font-family:cm; font-size:1.8em;\">Machine Learning</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c75c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59668be5",
   "metadata": {},
   "source": [
    "<p style=\"font-family:cm; font-size:1.4em;\">Logistic Regression</p>\n",
    "<br>\n",
    "<p style=\"font-family:cm; font-size:1em;\"> \n",
    "Logistic Regression is a ML model that is usually applied to linear data, in which every parameter is associated to a coefficient. It then plots a hyperplane in the 4d space formed by the 4 parameters in question. If a data point falls into one side of the hyperplane, it will be considered Dark Matter. If not, then it will be counted as background noise. <br>\n",
    "<br>\n",
    "At the end, the results are compared to the original labels and the accuracy is computed.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a4db51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6385\n"
     ]
    }
   ],
   "source": [
    "blind_data = data.drop('label', axis = 1) #Separating labels from the data\n",
    "answer = data[\"label\"] #Answers: 0 for background, 1 for DM\n",
    "\n",
    "#Separating train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(blind_data, \n",
    "                                                    answer, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=13)\n",
    "#Putting all into a same scale to avoid absolute value bias\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "#Applying Logistic Regression to the standardized dataset\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Computing the final accuracy of DM-signal separation\n",
    "accuracy = model.score(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65195d08",
   "metadata": {},
   "source": [
    "<p style=\"font-family:cm; font-size:1em;\">\n",
    "The result shows that it is, in fact, very difficult to distinguish between potential dark matter signals and background noise. If results were extremely precise, there would be a chance that the dataset is misleading, or rather the test data could be leaking into training data. This percentage is great for the scientific difficulty of the problem.\n",
    "</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
